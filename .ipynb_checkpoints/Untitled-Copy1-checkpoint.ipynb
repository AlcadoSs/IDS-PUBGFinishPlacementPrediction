{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_for_teams(data):\n",
    "    g_data = data.groupby(['groupId']).mean()\n",
    "    print(g_data.shape)\n",
    "\n",
    "    for i, groupId in zip(data.index, data['groupId']):\n",
    "        data.iloc[i][g_data.columns] = g_data.loc[groupId]\n",
    "    return data\n",
    "\n",
    "# features for duo or squad mode, these features are valued 0 in solo mode games\n",
    "def drop_team_features(data):\n",
    "    team_features = ['assists', 'DBNOs', 'revives', 'teamkills']\n",
    "    return data.drop(team_features, axis=1)\n",
    "\n",
    "def xy(data):\n",
    "    X = data.drop('winPlacePerc', axis = 1).select_dtypes(['number'])\n",
    "    y = data['winPlacePerc']\n",
    "    return X, y\n",
    "\n",
    "def fill_rankPoints(input_data, model = LinearRegression(), dropWinKillPoints=True):\n",
    "    work_data = input_data.copy()\n",
    "    work_data = pd.DataFrame(work_data.select_dtypes(['number']))\n",
    "\n",
    "    #drop the other point features, since these will not be useful in predicting rankPoints\n",
    "    work_data.drop(['winPoints', 'killPoints'], axis=1, inplace=True)\n",
    "\n",
    "    #train the model with data where there are rankPoints\n",
    "    train = pd.DataFrame(work_data.loc[data['rankPoints'] > 0, :])\n",
    "    X_train = train.drop('rankPoints', axis=1)\n",
    "    y_train = train['rankPoints']\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #use model to predict missing rankPoints\n",
    "    use = pd.DataFrame(work_data.loc[data['rankPoints'] <= 0, :])\n",
    "    X_use = use.drop('rankPoints', axis=1)\n",
    "    y_use = model.predict(X_use)\n",
    "\n",
    "    #fill in the missing data\n",
    "    work_data.loc[work_data['rankPoints'] <= 0, 'rankPoints'] = y_use\n",
    "\n",
    "    return work_data\n",
    "\n",
    "\n",
    "def print_top_feature_correlations_to_target_by_matchType(data, nrows):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    matchCounts = data['matchType'].value_counts().values.tolist()\n",
    "\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"Highest correlations to target feature BY matchType\")\n",
    "    print(\"Number of games:\", nrows, \"\\n\")\n",
    "    for cnt, mt in zip(matchCounts, matchTypes):\n",
    "        # for each matchtype\n",
    "        # look at all the rows for that matchtype\n",
    "        # and build a correlation matrix\n",
    "        corr = data \\\n",
    "            .drop('winPlacePerc', axis=1) \\\n",
    "            .loc[data['matchType'] == mt] \\\n",
    "            .corrwith(data.loc[data['matchType'] == mt]['winPlacePerc'])\n",
    "        corr = corr.sort_values(ascending=False)\n",
    "        print(\"Type:\", mt)\n",
    "        print(\"Nr of games:\", cnt)\n",
    "        print(corr.head())\n",
    "        print()\n",
    "\n",
    "\n",
    "def scoreSets(dfs, random_state=1):\n",
    "    for i, df in enumerate(dfs):\n",
    "        lr = LinearRegression()\n",
    "        x, y = xy(df)\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=random_state)\n",
    "        lr.fit(xtrain, ytrain)\n",
    "        print(\"Score for set nr: \", i+1, lr.score(xtest, ytest))\n",
    "\n",
    "def divide_by_matchType_and_aggregate_by_groupId(data):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    squadMatches = []\n",
    "    duoMatches = []\n",
    "    soloMatches = []\n",
    "    otherMatches = []\n",
    "    for match in matchTypes:\n",
    "        if 'squad' in match or 'flare' in match:\n",
    "            squadMatches.append(match)\n",
    "        elif 'duo' in match or 'crash' in match:\n",
    "            duoMatches.append(match)\n",
    "        elif 'solo' in match:\n",
    "            soloMatches.append(match)\n",
    "        else:\n",
    "            otherMatches.append(match)\n",
    "\n",
    "    squadSet = pd.DataFrame(data.loc[data['matchType'].isin(squadMatches),:])\n",
    "    duoSet = pd.DataFrame(data.loc[data['matchType'].isin(duoMatches),:])\n",
    "    soloSet = pd.DataFrame(data.loc[data['matchType'].isin(soloMatches),:])\n",
    "\n",
    "    squadMeanSet = pd.DataFrame(squadSet.groupby('groupId').mean(), dtype='float16')\n",
    "    duoMeanSet = pd.DataFrame(duoSet.groupby('groupId').mean(), dtype='float16')\n",
    "\n",
    "    squadSets = [squadSet, squadMeanSet]\n",
    "    duoSets = [duoSet, duoMeanSet]\n",
    "\n",
    "    #print(\"Returning [[squadSet, squadMeanSet], [duoSet, duoMeanSet], soloSet]\")\n",
    "    return [squadSets, duoSets, soloSet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign dtypes to minimize memory usage\n",
    "dtypes = {\n",
    "    'Id': 'object',\n",
    "    'groupId': 'object',\n",
    "    'matchId': 'object',\n",
    "    'assists': 'uint8',\n",
    "    'boosts': 'uint8',\n",
    "    'damageDealt': 'float16',\n",
    "    'DBNOs': 'uint8',\n",
    "    'headshotKills': 'uint8',\n",
    "    'heals': 'uint8',\n",
    "    'killPlace': 'uint8',\n",
    "    'killPoints': 'uint16',\n",
    "    'kills': 'uint8',\n",
    "    'killStreaks': 'uint8',\n",
    "    'longestKill': 'float16',\n",
    "    'maxPlace': 'uint8',\n",
    "    'numGroups': 'uint8',\n",
    "    'revives': 'uint8',\n",
    "    'rideDistance': 'float16',\n",
    "    'roadKills': 'uint8',\n",
    "    'swimDistance': 'float16',\n",
    "    'teamKills': 'uint8',\n",
    "    'vehicleDestroys': 'uint8',\n",
    "    'walkDistance': 'float16',\n",
    "    'weaponsAcquired': 'uint8',\n",
    "    'winPoints': 'uint8',\n",
    "    'winPlacePerc': 'float16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_V2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d33af996710f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_V2.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_V2.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDS\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDS\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDS\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDS\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\IDS\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_V2.csv'"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train_V2.csv\", dtype=dtypes)\n",
    "test_data = pd.read_csv(\"test_V2.csv\", dtype=dtypes)\n",
    "\n",
    "print(train_data.loc[:, train_data.isnull().any()].columns)\n",
    "print(test_data.loc[:, test_data.isnull().any()].columns)\n",
    "\n",
    "train_data[train_data['winPlacePerc'].isnull()]\n",
    "train_data = train_data.dropna(subset=['winPlacePerc'])\n",
    "train_data[train_data['winPlacePerc'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traino = train_data.copy()\n",
    "testo = test_data.copy()\n",
    "#traino = traino[['matchType','groupId','kills', 'damageDealt', 'killPlace', 'walkDistance', 'weaponsAcquired', 'boosts', 'heals', 'winPlacePerc']]\n",
    "#testo = testo[['matchType','groupId','kills', 'damageDealt', 'killPlace', 'walkDistance', 'weaponsAcquired', 'boosts', 'heals']]\n",
    "\n",
    "traino = train_data[:4000000]\n",
    "testo = train_data[4000000:-1]\n",
    "testo_y = testo.winPlacePerc\n",
    "testo = testo.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSets = divide_by_matchType_and_aggregate_by_groupId(traino)\n",
    "testSets = divide_by_matchType_and_aggregate_by_groupId(testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solo_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "#duo_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "#squad_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "\n",
    "solo_mod = LinearRegression()\n",
    "duo_mod = LinearRegression()\n",
    "squad_mod = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#testSets = divide_by_matchType_and_aggregate_by_groupId(test)\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "all_predictions = pd.DataFrame()\n",
    "for train, test, model in zip(trainSets, testSets, models):\n",
    "    if len(train) == 2:\n",
    "        trainset = train[0]\n",
    "        meanTrainSet = train[1] #only numeric values, the index is 'groupId'\n",
    "        testset = test[0]\n",
    "        X_test = test[1]\n",
    "\n",
    "        X_train = meanTrainSet.drop('winPlacePerc', axis=1)\n",
    "        y_train = meanTrainSet.winPlacePerc\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        #now I will rejoin the prediction with the original row index\n",
    "        yhat = pd.DataFrame(yhat, index=X_test.index,columns=['prediction'])\n",
    "        testset = testset.join(yhat, on='groupId')\n",
    "        yhat = testset.drop(testset.columns.difference(['prediction']), axis=1)\n",
    "\n",
    "    else:\n",
    "        X_train = train.select_dtypes(['number']).drop('winPlacePerc', axis=1)\n",
    "        y_train = train.winPlacePerc\n",
    "        X_test = pd.DataFrame(test.select_dtypes(['number']))\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        X_test['prediction'] = yhat\n",
    "        yhat = pd.DataFrame(X_test['prediction'], index=X_test.index, dtype='float32')\n",
    "\n",
    "    all_predictions = all_predictions.append(yhat)\n",
    "\n",
    "all_predictions.sort_index(inplace=True)\n",
    "print(all_predictions.shape, testset.shape)\n",
    "print(all_predictions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data. If memory is not an issue, lose the nrows parameter\n",
    "nrows = 2500000\n",
    "train = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/train_V2.csv\", nrows=nrows, dtype=dtypes)\n",
    "test = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/test_V2.csv\", nrows=nrows, dtype=dtypes)\n",
    "\n",
    "\n",
    "trainSets = divide_by_matchType_and_aggregate_by_groupId(train)\n",
    "testSets = divide_by_matchType_and_aggregate_by_groupId(test)\n",
    "models = [LinearRegression(), LinearRegression(), LinearRegression()]\n",
    "\n",
    "all_predictions = pd.DataFrame()\n",
    "for train, test, model in zip(trainSets, testSets, models):\n",
    "    if len(train) == 2:\n",
    "        trainset = train[0]\n",
    "        meanTrainSet = train[1] #only numeric values, the index is 'groupId'\n",
    "        testset = test[0]\n",
    "        X_test = test[1]\n",
    "\n",
    "        X_train = meanTrainSet.drop('winPlacePerc', axis=1)\n",
    "        y_train = meanTrainSet.winPlacePerc\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        #now I will rejoin the prediction with the original row index\n",
    "        yhat = pd.DataFrame(yhat, index=X_test.index,columns=['prediction'])\n",
    "        testset = testset.join(yhat, on='groupId')\n",
    "        yhat = testset.drop(testset.columns.difference(['prediction']), axis=1)\n",
    "\n",
    "    else:\n",
    "        X_train = train.select_dtypes(['number']).drop('winPlacePerc', axis=1)\n",
    "        y_train = train.winPlacePerc\n",
    "        X_test = pd.DataFrame(test.select_dtypes(['number']))\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        X_test['prediction'] = yhat\n",
    "        yhat = pd.DataFrame(X_test['prediction'], index=X_test.index, dtype='float32')\n",
    "\n",
    "    all_predictions = all_predictions.append(yhat)\n",
    "\n",
    "all_predictions.sort_index(inplace=True)\n",
    "print(all_predictions.shape, testset.shape)\n",
    "print(all_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-975265f58c46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#split the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'winPlacePerc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'winPlacePerc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "X=train_data.drop(['winPlacePerc'],axis=1)\n",
    "y=train_data['winPlacePerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
