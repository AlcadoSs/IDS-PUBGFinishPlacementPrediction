{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code used in Kaggle for testing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "// assign dtypes to minimize memory usage\n",
    "dtypes = {\n",
    "    'Id': 'object',\n",
    "    'groupId': 'object',\n",
    "    'matchId': 'object',\n",
    "    'assists': 'uint8',\n",
    "    'boosts': 'uint8',\n",
    "    'damageDealt': 'float16',\n",
    "    'DBNOs': 'uint8',\n",
    "    'headshotKills': 'uint8',\n",
    "    'heals': 'uint8',\n",
    "    'killPlace': 'uint8',\n",
    "    'killPoints': 'uint16',\n",
    "    'kills': 'uint8',\n",
    "    'killStreaks': 'uint8',\n",
    "    'longestKill': 'float16',\n",
    "    'maxPlace': 'uint8',\n",
    "    'numGroups': 'uint8',\n",
    "    'revives': 'uint8',\n",
    "    'rideDistance': 'float16',\n",
    "    'roadKills': 'uint8',\n",
    "    'swimDistance': 'float16',\n",
    "    'teamKills': 'uint8',\n",
    "    'vehicleDestroys': 'uint8',\n",
    "    'walkDistance': 'float16',\n",
    "    'weaponsAcquired': 'uint8',\n",
    "    'winPoints': 'uint8',\n",
    "    'winPlacePerc': 'float16'\n",
    "}\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/train_V2.csv\", dtype=dtypes)\n",
    "test_data = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/test_V2.csv\", dtype=dtypes)\n",
    "\n",
    "print(train_data.loc[:, train_data.isnull().any()].columns)\n",
    "print(test_data.loc[:, test_data.isnull().any()].columns)\n",
    "\n",
    "train_data[train_data['winPlacePerc'].isnull()]\n",
    "train_data = train_data.dropna(subset=['winPlacePerc'])\n",
    "train_data[train_data['winPlacePerc'].isnull()]\n",
    "\n",
    "#split the data\n",
    "data_train = train_data.copy()\n",
    "data_test = test_data.copy()\n",
    "data_train.drop(['Id','groupId','matchId', 'matchType'],axis=1,inplace=True)\n",
    "data_test.drop(['Id','groupId','matchId', 'matchType'],axis=1,inplace=True)\n",
    "X=data_train.drop(['winPlacePerc'],axis=1)\n",
    "y=data_train['winPlacePerc']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)\n",
    "\n",
    "# 1\n",
    "regression = LinearRegression()\n",
    "# 2\n",
    "#regression = Lasso() \n",
    "# 3\n",
    "#regression = Ridge()\n",
    "# 4\n",
    "# regression = RandomForestRegressor()\n",
    "# 5\n",
    "# regression = lightgbm.LGBMRegressor()\n",
    "\n",
    "regression.fit(X_train, y_train)\n",
    "predictions = regression.predict(data_test)\n",
    "sub = pd.read_csv(r'/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv')\n",
    "sub['winPlacePerc'] = predictions\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression mse was 0.09171 on testset without any preprocessing and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso mse was 0.12045 on testset without any preprocessing and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge mse was 0.09171 on testset without any preprocessing and parameters tuning.Same as Linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor mse was 0.06841 on testset without any preprocessing and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM mse was 0.05970 on testset without any preprocessing and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models mse with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code used in Kaggle for testing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import lightgbm as lgbm\n",
    "\n",
    "def means_for_teams(data):\n",
    "    g_data = data.groupby(['groupId']).mean()\n",
    "    print(g_data.shape)\n",
    "\n",
    "    for i, groupId in zip(data.index, data['groupId']):\n",
    "        data.iloc[i][g_data.columns] = g_data.loc[groupId]\n",
    "    return data\n",
    "\n",
    "# features for duo or squad mode, these features are valued 0 in solo mode games\n",
    "def drop_team_features(data):\n",
    "    team_features = ['assists', 'DBNOs', 'revives', 'teamkills']\n",
    "    return data.drop(team_features, axis=1)\n",
    "\n",
    "def xy(data):\n",
    "    X = data.drop('winPlacePerc', axis = 1).select_dtypes(['number'])\n",
    "    y = data['winPlacePerc']\n",
    "    return X, y\n",
    "\n",
    "def fill_rankPoints(input_data, model = LinearRegression(), dropWinKillPoints=True):\n",
    "    work_data = input_data.copy()\n",
    "    work_data = pd.DataFrame(work_data.select_dtypes(['number']))\n",
    "\n",
    "    #drop the other point features, since these will not be useful in predicting rankPoints\n",
    "    work_data.drop(['winPoints', 'killPoints'], axis=1, inplace=True)\n",
    "\n",
    "    #train the model with data where there are rankPoints\n",
    "    train = pd.DataFrame(work_data.loc[data['rankPoints'] > 0, :])\n",
    "    X_train = train.drop('rankPoints', axis=1)\n",
    "    y_train = train['rankPoints']\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #use model to predict missing rankPoints\n",
    "    use = pd.DataFrame(work_data.loc[data['rankPoints'] <= 0, :])\n",
    "    X_use = use.drop('rankPoints', axis=1)\n",
    "    y_use = model.predict(X_use)\n",
    "\n",
    "    #fill in the missing data\n",
    "    work_data.loc[work_data['rankPoints'] <= 0, 'rankPoints'] = y_use\n",
    "\n",
    "    return work_data\n",
    "\n",
    "\n",
    "def print_top_feature_correlations_to_target_by_matchType(data, nrows):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    matchCounts = data['matchType'].value_counts().values.tolist()\n",
    "\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"Highest correlations to target feature BY matchType\")\n",
    "    print(\"Number of games:\", nrows, \"\\n\")\n",
    "    for cnt, mt in zip(matchCounts, matchTypes):\n",
    "        # for each matchtype\n",
    "        # look at all the rows for that matchtype\n",
    "        # and build a correlation matrix\n",
    "        corr = data \\\n",
    "            .drop('winPlacePerc', axis=1) \\\n",
    "            .loc[data['matchType'] == mt] \\\n",
    "            .corrwith(data.loc[data['matchType'] == mt]['winPlacePerc'])\n",
    "        corr = corr.sort_values(ascending=False)\n",
    "        print(\"Type:\", mt)\n",
    "        print(\"Nr of games:\", cnt)\n",
    "        print(corr.head())\n",
    "        print()\n",
    "\n",
    "\n",
    "def scoreSets(dfs, random_state=1):\n",
    "    for i, df in enumerate(dfs):\n",
    "        lr = LinearRegression()\n",
    "        x, y = xy(df)\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=random_state)\n",
    "        lr.fit(xtrain, ytrain)\n",
    "        print(\"Score for set nr: \", i+1, lr.score(xtest, ytest))\n",
    "\n",
    "def divide_by_matchType_and_aggregate_by_groupId(data):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    squadMatches = []\n",
    "    duoMatches = []\n",
    "    soloMatches = []\n",
    "    otherMatches = []\n",
    "    for match in matchTypes:\n",
    "        if 'squad' in match or 'flare' in match:\n",
    "            squadMatches.append(match)\n",
    "        elif 'duo' in match or 'crash' in match:\n",
    "            duoMatches.append(match)\n",
    "        elif 'solo' in match:\n",
    "            soloMatches.append(match)\n",
    "        else:\n",
    "            otherMatches.append(match)\n",
    "\n",
    "    squadSet = pd.DataFrame(data.loc[data['matchType'].isin(squadMatches),:])\n",
    "    duoSet = pd.DataFrame(data.loc[data['matchType'].isin(duoMatches),:])\n",
    "    soloSet = pd.DataFrame(data.loc[data['matchType'].isin(soloMatches),:])\n",
    "\n",
    "    squadMeanSet = pd.DataFrame(squadSet.groupby('groupId').mean(), dtype='float16')\n",
    "    duoMeanSet = pd.DataFrame(duoSet.groupby('groupId').mean(), dtype='float16')\n",
    "\n",
    "    squadSets = [squadSet, squadMeanSet]\n",
    "    duoSets = [duoSet, duoMeanSet]\n",
    "\n",
    "    #print(\"Returning [[squadSet, squadMeanSet], [duoSet, duoMeanSet], soloSet]\")\n",
    "    return [squadSets, duoSets, soloSet]\n",
    "\n",
    "\n",
    "# assign dtypes to minimize memory usage\n",
    "dtypes = {\n",
    "    'Id': 'object',\n",
    "    'groupId': 'object',\n",
    "    'matchId': 'object',\n",
    "    'assists': 'uint8',\n",
    "    'boosts': 'uint8',\n",
    "    'damageDealt': 'float16',\n",
    "    'DBNOs': 'uint8',\n",
    "    'headshotKills': 'uint8',\n",
    "    'heals': 'uint8',\n",
    "    'killPlace': 'uint8',\n",
    "    'killPoints': 'uint16',\n",
    "    'kills': 'uint8',\n",
    "    'killStreaks': 'uint8',\n",
    "    'longestKill': 'float16',\n",
    "    'maxPlace': 'uint8',\n",
    "    'numGroups': 'uint8',\n",
    "    'revives': 'uint8',\n",
    "    'rideDistance': 'float16',\n",
    "    'roadKills': 'uint8',\n",
    "    'swimDistance': 'float16',\n",
    "    'teamKills': 'uint8',\n",
    "    'vehicleDestroys': 'uint8',\n",
    "    'walkDistance': 'float16',\n",
    "    'weaponsAcquired': 'uint8',\n",
    "    'winPoints': 'uint8',\n",
    "    'winPlacePerc': 'float16'\n",
    "}\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/train_V2.csv\", dtype=dtypes)\n",
    "test_data = pd.read_csv(\"/kaggle/input/pubg-finish-placement-prediction/test_V2.csv\", dtype=dtypes)\n",
    "\n",
    "#print(train_data.loc[:, train_data.isnull().any()].columns)\n",
    "#print(test_data.loc[:, test_data.isnull().any()].columns)\n",
    "\n",
    "train_data[train_data['winPlacePerc'].isnull()]\n",
    "\n",
    "train_data = train_data.dropna(subset=['winPlacePerc'])\n",
    "\n",
    "#train_data[train_data['winPlacePerc'].isnull()]\n",
    "\n",
    "# train_data - Training data with feature \"winPlacePerc\"\n",
    "# test_data - Testing data without feature \"winPlacePerc\"\n",
    "# models - models for solo, dua and squad prediction as list [model for solo, model for duo, model for squad]\n",
    "\n",
    "def testPredictions(train_data, test_data, models):\n",
    "\n",
    "    train = train_data\n",
    "    test = test_data\n",
    "   \n",
    "    trainSets = divide_by_matchType_and_aggregate_by_groupId(train)\n",
    "    testSets = divide_by_matchType_and_aggregate_by_groupId(test)\n",
    "    \n",
    "    all_predictions = pd.DataFrame()\n",
    "    for train, test, model in zip(trainSets, testSets, models):\n",
    "        if len(train) == 2:\n",
    "            trainset = train[0]\n",
    "            meanTrainSet = train[1] #only numeric values, the index is 'groupId'\n",
    "            testset = test[0]\n",
    "            X_test = test[1]\n",
    "\n",
    "            X_train = meanTrainSet.drop('winPlacePerc', axis=1)\n",
    "            y_train = meanTrainSet.winPlacePerc\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            yhat = model.predict(X_test)\n",
    "\n",
    "            #now I will rejoin the prediction with the original row index\n",
    "            yhat = pd.DataFrame(yhat, index=X_test.index,columns=['prediction'])\n",
    "            testset = testset.join(yhat, on='groupId')\n",
    "            yhat = testset.drop(testset.columns.difference(['prediction']), axis=1)\n",
    "\n",
    "        else:\n",
    "            X_train = train.select_dtypes(['number']).drop('winPlacePerc', axis=1)\n",
    "            y_train = train.winPlacePerc\n",
    "            X_test = pd.DataFrame(test.select_dtypes(['number']))\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            yhat = model.predict(X_test)\n",
    "\n",
    "            X_test['prediction'] = yhat\n",
    "            yhat = pd.DataFrame(X_test['prediction'], index=X_test.index, dtype='float32')\n",
    "\n",
    "        all_predictions = all_predictions.append(yhat)\n",
    "\n",
    "    all_predictions.sort_index(inplace=True)\n",
    "\n",
    "    return all_predictions\n",
    "\n",
    "\n",
    "# 1\n",
    "solo_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "duo_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "squad_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "\n",
    "# 2\n",
    "#solo_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001, max_iter = 2500)\n",
    "#duo_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001, max_iter = 2500)\n",
    "#squad_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001, max_iter = 2500)\n",
    "\n",
    "# 3\n",
    "#solo_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol =  0.001, solver = 'auto')\n",
    "#duo_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol =  0.001, solver = 'auto')\n",
    "#squad_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol =  0.001, solver = 'auto')\n",
    "\n",
    "# 4\n",
    "#solo_mod = RandomForestRegressor(n_estimators=150, max_features=0.5,min_samples_split = 2, min_samples_leaf=3, n_jobs=-1,verbose=2)\n",
    "#duo_mod = RandomForestRegressor(n_estimators=150, max_features=0.5,min_samples_split = 2, min_samples_leaf=3, n_jobs=-1, verbose=2)\n",
    "#squad_mod = RandomForestRegressor(n_estimators=150, max_features=0.5,min_samples_split = 2, min_samples_leaf=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 5\n",
    "#solo_mod = lightgbm.LGBMRegressor(objective = \"regression\",metric = \"mae\",num_leaves =  128,verbose =  1, n_estimators=150)\n",
    "#duo_mod = lightgbm.LGBMRegressor(objective = \"regression\",metric = \"mae\",num_leaves =  128,verbose =  1, n_estimators=150)\n",
    "#squad_mod = lightgbm.LGBMRegressor(objective = \"regression\",metric = \"mae\",num_leaves =  128,verbose =  1, n_estimators=150)\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data\n",
    "test_d = test_data\n",
    "\n",
    "all_predictions = testPredictions(train_d, test_d, models)\n",
    "sub = pd.read_csv(r'/kaggle/input/pubg-finish-placement-prediction/sample_submission_V2.csv')\n",
    "sub['winPlacePerc'] = all_predictions['prediction']\n",
    "sub['winPlacePerc'] = predictions\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression mse was 0.07170 on testset with preprocressing(matchType seperately) and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso mse was 0.07473 on testset with preprocressing(matchType seperately) and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge mse was 0.0695 on testset with preprocressing(matchType seperately) and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor mse was 0.05202 on testset with preprocressing(matchType seperately) and parameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with preprocressing(matchType seperately) and parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest Regressor mse was 0.05034 on testset with preprocressing(matchType seperately) and parameters tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
