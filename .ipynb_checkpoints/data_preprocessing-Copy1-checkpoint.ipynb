{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_for_teams(data):\n",
    "    g_data = data.groupby(['groupId']).mean()\n",
    "    print(g_data.shape)\n",
    "\n",
    "    for i, groupId in zip(data.index, data['groupId']):\n",
    "        data.iloc[i][g_data.columns] = g_data.loc[groupId]\n",
    "    return data\n",
    "\n",
    "# features for duo or squad mode, these features are valued 0 in solo mode games\n",
    "def drop_team_features(data):\n",
    "    team_features = ['assists', 'DBNOs', 'revives', 'teamkills']\n",
    "    return data.drop(team_features, axis=1)\n",
    "\n",
    "def xy(data):\n",
    "    X = data.drop('winPlacePerc', axis = 1).select_dtypes(['number'])\n",
    "    y = data['winPlacePerc']\n",
    "    return X, y\n",
    "\n",
    "def fill_rankPoints(input_data, model = LinearRegression(), dropWinKillPoints=True):\n",
    "    work_data = input_data.copy()\n",
    "    work_data = pd.DataFrame(work_data.select_dtypes(['number']))\n",
    "\n",
    "    #drop the other point features, since these will not be useful in predicting rankPoints\n",
    "    work_data.drop(['winPoints', 'killPoints'], axis=1, inplace=True)\n",
    "\n",
    "    #train the model with data where there are rankPoints\n",
    "    train = pd.DataFrame(work_data.loc[data['rankPoints'] > 0, :])\n",
    "    X_train = train.drop('rankPoints', axis=1)\n",
    "    y_train = train['rankPoints']\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #use model to predict missing rankPoints\n",
    "    use = pd.DataFrame(work_data.loc[data['rankPoints'] <= 0, :])\n",
    "    X_use = use.drop('rankPoints', axis=1)\n",
    "    y_use = model.predict(X_use)\n",
    "\n",
    "    #fill in the missing data\n",
    "    work_data.loc[work_data['rankPoints'] <= 0, 'rankPoints'] = y_use\n",
    "\n",
    "    return work_data\n",
    "\n",
    "\n",
    "def print_top_feature_correlations_to_target_by_matchType(data, nrows):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    matchCounts = data['matchType'].value_counts().values.tolist()\n",
    "\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    print(\"Highest correlations to target feature BY matchType\")\n",
    "    print(\"Number of games:\", nrows, \"\\n\")\n",
    "    for cnt, mt in zip(matchCounts, matchTypes):\n",
    "        # for each matchtype\n",
    "        # look at all the rows for that matchtype\n",
    "        # and build a correlation matrix\n",
    "        corr = data \\\n",
    "            .drop('winPlacePerc', axis=1) \\\n",
    "            .loc[data['matchType'] == mt] \\\n",
    "            .corrwith(data.loc[data['matchType'] == mt]['winPlacePerc'])\n",
    "        corr = corr.sort_values(ascending=False)\n",
    "        print(\"Type:\", mt)\n",
    "        print(\"Nr of games:\", cnt)\n",
    "        print(corr.head())\n",
    "        print()\n",
    "\n",
    "\n",
    "def scoreSets(dfs, random_state=1):\n",
    "    for i, df in enumerate(dfs):\n",
    "        lr = LinearRegression()\n",
    "        x, y = xy(df)\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=random_state)\n",
    "        lr.fit(xtrain, ytrain)\n",
    "        print(\"Score for set nr: \", i+1, lr.score(xtest, ytest))\n",
    "\n",
    "def divide_by_matchType_and_aggregate_by_groupId(data):\n",
    "    matchTypes = data['matchType'].value_counts().index.tolist()\n",
    "    squadMatches = []\n",
    "    duoMatches = []\n",
    "    soloMatches = []\n",
    "    otherMatches = []\n",
    "    for match in matchTypes:\n",
    "        if 'squad' in match or 'flare' in match:\n",
    "            squadMatches.append(match)\n",
    "        elif 'duo' in match or 'crash' in match:\n",
    "            duoMatches.append(match)\n",
    "        elif 'solo' in match:\n",
    "            soloMatches.append(match)\n",
    "        else:\n",
    "            otherMatches.append(match)\n",
    "\n",
    "    squadSet = pd.DataFrame(data.loc[data['matchType'].isin(squadMatches),:])\n",
    "    duoSet = pd.DataFrame(data.loc[data['matchType'].isin(duoMatches),:])\n",
    "    soloSet = pd.DataFrame(data.loc[data['matchType'].isin(soloMatches),:])\n",
    "\n",
    "    squadMeanSet = pd.DataFrame(squadSet.groupby('groupId').mean(), dtype='float16')\n",
    "    duoMeanSet = pd.DataFrame(duoSet.groupby('groupId').mean(), dtype='float16')\n",
    "\n",
    "    squadSets = [squadSet, squadMeanSet]\n",
    "    duoSets = [duoSet, duoMeanSet]\n",
    "\n",
    "    #print(\"Returning [[squadSet, squadMeanSet], [duoSet, duoMeanSet], soloSet]\")\n",
    "    return [squadSets, duoSets, soloSet]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign dtypes to minimize memory usage\n",
    "dtypes = {\n",
    "    'Id': 'object',\n",
    "    'groupId': 'object',\n",
    "    'matchId': 'object',\n",
    "    'assists': 'uint8',\n",
    "    'boosts': 'uint8',\n",
    "    'damageDealt': 'float16',\n",
    "    'DBNOs': 'uint8',\n",
    "    'headshotKills': 'uint8',\n",
    "    'heals': 'uint8',\n",
    "    'killPlace': 'uint8',\n",
    "    'killPoints': 'uint16',\n",
    "    'kills': 'uint8',\n",
    "    'killStreaks': 'uint8',\n",
    "    'longestKill': 'float16',\n",
    "    'maxPlace': 'uint8',\n",
    "    'numGroups': 'uint8',\n",
    "    'revives': 'uint8',\n",
    "    'rideDistance': 'float16',\n",
    "    'roadKills': 'uint8',\n",
    "    'swimDistance': 'float16',\n",
    "    'teamKills': 'uint8',\n",
    "    'vehicleDestroys': 'uint8',\n",
    "    'walkDistance': 'float16',\n",
    "    'weaponsAcquired': 'uint8',\n",
    "    'winPoints': 'uint8',\n",
    "    'winPlacePerc': 'float16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['winPlacePerc'], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>groupId</th>\n",
       "      <th>matchId</th>\n",
       "      <th>assists</th>\n",
       "      <th>boosts</th>\n",
       "      <th>damageDealt</th>\n",
       "      <th>DBNOs</th>\n",
       "      <th>headshotKills</th>\n",
       "      <th>heals</th>\n",
       "      <th>killPlace</th>\n",
       "      <th>...</th>\n",
       "      <th>revives</th>\n",
       "      <th>rideDistance</th>\n",
       "      <th>roadKills</th>\n",
       "      <th>swimDistance</th>\n",
       "      <th>teamKills</th>\n",
       "      <th>vehicleDestroys</th>\n",
       "      <th>walkDistance</th>\n",
       "      <th>weaponsAcquired</th>\n",
       "      <th>winPoints</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, groupId, matchId, assists, boosts, damageDealt, DBNOs, headshotKills, heals, killPlace, killPoints, kills, killStreaks, longestKill, matchDuration, matchType, maxPlace, numGroups, rankPoints, revives, rideDistance, roadKills, swimDistance, teamKills, vehicleDestroys, walkDistance, weaponsAcquired, winPoints, winPlacePerc]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train_V2.csv\", dtype=dtypes)\n",
    "test_data = pd.read_csv(\"test_V2.csv\", dtype=dtypes)\n",
    "\n",
    "print(train_data.loc[:, train_data.isnull().any()].columns)\n",
    "print(test_data.loc[:, test_data.isnull().any()].columns)\n",
    "\n",
    "train_data[train_data['winPlacePerc'].isnull()]\n",
    "train_data = train_data.dropna(subset=['winPlacePerc'])\n",
    "train_data[train_data['winPlacePerc'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data - Training data with feature \"winPlacePerc\"\n",
    "# test_data - Testing data without feature \"winPlacePerc\"\n",
    "# models - models for solo, dua and squad prediction as list [model for solo, model for duo, model for squad]\n",
    "# test_data_y - Testing data feature \"winPlacePerc\" values to find MSE, if not added, function returns only dataframe with predicted values\n",
    "\n",
    "def modelMSE(train_data, test_data, models, test_data_y=None):\n",
    "\n",
    "    train = train_data\n",
    "    test = test_data\n",
    "   \n",
    "    trainSets = divide_by_matchType_and_aggregate_by_groupId(train)\n",
    "    testSets = divide_by_matchType_and_aggregate_by_groupId(test)\n",
    "    \n",
    "    all_predictions = pd.DataFrame()\n",
    "    for train, test, model in zip(trainSets, testSets, models):\n",
    "        if len(train) == 2:\n",
    "            trainset = train[0]\n",
    "            meanTrainSet = train[1] #only numeric values, the index is 'groupId'\n",
    "            testset = test[0]\n",
    "            X_test = test[1]\n",
    "\n",
    "            X_train = meanTrainSet.drop('winPlacePerc', axis=1)\n",
    "            y_train = meanTrainSet.winPlacePerc\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            yhat = model.predict(X_test)\n",
    "\n",
    "            #now I will rejoin the prediction with the original row index\n",
    "            yhat = pd.DataFrame(yhat, index=X_test.index,columns=['prediction'])\n",
    "            testset = testset.join(yhat, on='groupId')\n",
    "            yhat = testset.drop(testset.columns.difference(['prediction']), axis=1)\n",
    "\n",
    "        else:\n",
    "            X_train = train.select_dtypes(['number']).drop('winPlacePerc', axis=1)\n",
    "            y_train = train.winPlacePerc\n",
    "            X_test = pd.DataFrame(test.select_dtypes(['number']))\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            yhat = model.predict(X_test)\n",
    "\n",
    "            X_test['prediction'] = yhat\n",
    "            yhat = pd.DataFrame(X_test['prediction'], index=X_test.index, dtype='float32')\n",
    "\n",
    "        all_predictions = all_predictions.append(yhat)\n",
    "\n",
    "    all_predictions.sort_index(inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    if (test_data_y is None):\n",
    "        return all_predictions, 0\n",
    "    else:\n",
    "        MSE = mean_squared_error(all_predictions,test_data_y)\n",
    "        return all_predictions, MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "train_data_copy = train_data.copy()\n",
    "train_data_copy.drop(['Id','groupId','matchId', 'matchType'],axis=1,inplace=True)\n",
    "X=train_data_copy.drop(['winPlacePerc'],axis=1)\n",
    "y=train_data_copy['winPlacePerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10,random_state=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11544423, 0.28815191, 0.66781507, ..., 0.69298808, 0.15335417,\n",
       "       0.24849936])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = linear_regression.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0161167674846259"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test.values,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with placement for Solo, Duo and Squad games are found separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = LinearRegression()\n",
    "duo_mod = LinearRegression()\n",
    "squad_mod = LinearRegression()\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0114928745"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Linear Regression Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'fit_intercept':[True,False],'normalize':[True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "grid_search= GridSearchCV(linear_regression,params,cv=3,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data.drop(['matchType','Id','groupId','matchId'],axis=1,inplace=True)\n",
    "X=data.drop(['winPlacePerc'],axis=1)\n",
    "y=data['winPlacePerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LinearRegression(),\n",
       "             param_grid={'fit_intercept': [True, False],\n",
       "                         'normalize': [True, False]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X[:1000000],y[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True, 'normalize': False}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "duo_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "squad_mod = LinearRegression(fit_intercept = True, normalize = False, n_jobs = -1)\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0114928745"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500001    0.718750\n",
       "3500002    0.208252\n",
       "3500003    0.104187\n",
       "3500004    0.911133\n",
       "3500005    0.115417\n",
       "             ...   \n",
       "4446960    0.241455\n",
       "4446961    0.178589\n",
       "4446962    0.293457\n",
       "4446963    0.481445\n",
       "4446964    0.799805\n",
       "Name: winPlacePerc, Length: 946964, dtype: float16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = Lasso()\n",
    "duo_mod = Lasso()\n",
    "squad_mod = Lasso()\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020356419178780123"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'alpha':[1,0.1,0.001,0.0001], 'normalize':[True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_regression = Lasso()\n",
    "grid_search= GridSearchCV(lasso_regression,params,cv=3,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data.drop(['matchType','Id','groupId','matchId'],axis=1,inplace=True)\n",
    "X=data.drop(['winPlacePerc'],axis=1)\n",
    "y=data['winPlacePerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 287.8800292379983, tolerance: 6.306178493891602\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299.4949626307298, tolerance: 6.298401157414082\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310.2717590052762, tolerance: 6.304082994871063\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3126.485826159665, tolerance: 6.306178493891602\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3160.8350516532937, tolerance: 6.298401157414082\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3187.425988357035, tolerance: 6.304082994871063\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Maasikas\\miniconda3\\envs\\IDS\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4737.896063112374, tolerance: 9.454334211006698\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1, 0.1, 0.001, 0.0001],\n",
       "                         'normalize': [True, False]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X[:1000000],y[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'normalize': False}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001)\n",
    "duo_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001)\n",
    "squad_mod = Lasso(fit_intercept = True, normalize = False, alpha = 0.0001)\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011497869267820248"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = Ridge()\n",
    "duo_mod = Ridge()\n",
    "squad_mod = Ridge()\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011492588506364029"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'alpha':[1,0.1,0.001,0.0001], 'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], 'normalize':[True,False], 'tol':[0.1,0.01, 0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_regression = Ridge()\n",
    "grid_search= GridSearchCV(ridge_regression,params,cv=3,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.copy()\n",
    "data.drop(['matchType','Id','groupId','matchId'],axis=1,inplace=True)\n",
    "X=data.drop(['winPlacePerc'],axis=1)\n",
    "y=data['winPlacePerc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Ridge(),\n",
       "             param_grid={'alpha': [1, 0.1, 0.001, 0.0001],\n",
       "                         'normalize': [True, False], 'solver': ['auto', 'svd'],\n",
       "                         'tol': [0.1, 0.01, 0.001]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X[:1000000],y[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'normalize': False, 'solver': 'auto', 'tol': 0.1}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol =  0.01, solver = 'auto')\n",
    "duo_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol =  0.01, solver = 'auto')\n",
    "squad_mod = Ridge(fit_intercept = True, normalize = False, alpha = 1, tol = 0.01, solver = 'auto')\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013325663065541424"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solo_mod = RandomForestRegressor(n_estimators=10,  min_samples_split=2, min_samples_leaf = 1, max_features='sqrt', max_depth = None, bootstrap = False,  n_jobs=-1, verbose=1) #max_features=0.5,\n",
    "#duo_mod = RandomForestRegressor(n_estimators=10,  min_samples_split=2, min_samples_leaf = 1, max_features='sqrt', max_depth = None, bootstrap = False,  n_jobs=-1, verbose=1)\n",
    "#squad_mod = RandomForestRegressor(n_estimators=10,  min_samples_split=2, min_samples_leaf = 1, max_features='sqrt', max_depth = None, bootstrap = False,  n_jobs=-1, verbose=1)\n",
    "\n",
    "solo_mod  = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "duo_mod  = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "squad_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    " \n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         prediction\n",
       " 2223482    0.894972\n",
       " 2223483    0.628783\n",
       " 2223484    0.694081\n",
       " 2223485    0.940858\n",
       " 2223486    0.072896\n",
       " ...             ...\n",
       " 4446960    0.258654\n",
       " 4446961    0.387337\n",
       " 4446962    0.319424\n",
       " 4446963    0.393011\n",
       " 4446964    0.865053\n",
       " \n",
       " [2223482 rows x 1 columns],\n",
       " 0.0060317956063010575)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 150, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt', '0.5']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 14, 18, 23, 27, 32,\n",
       "                                                      36, 41, 45, 50, None],\n",
       "                                        'max_features': ['sqrt', '0.5'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [1, 17, 34, 50, 67, 83,\n",
       "                                                         100, 116, 133, 150]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_data.copy()\n",
    "data.drop(['matchType','Id','groupId','matchId'],axis=1,inplace=True)\n",
    "X=data.drop(['winPlacePerc'],axis=1)\n",
    "y=data['winPlacePerc']\n",
    "\n",
    "train_features = X[:100000]\n",
    "train_labels = y[:100000]\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n",
    "\n",
    "#1000- {'n_estimators': 155,'min_samples_split': 2,'min_samples_leaf': 1,'max_features': 'auto','max_depth': 32,'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod  = RandomForestRegressor(n_estimators=150, max_features='sqrt',min_samples_split = 4, min_samples_leaf=3, n_jobs=-1)\n",
    "duo_mod  = RandomForestRegressor(n_estimators=150, max_features='sqrt', min_samples_split = 4, min_samples_leaf=3, n_jobs=-1)\n",
    "squad_mod = RandomForestRegressor(n_estimators=150, max_features='sqrt',min_samples_split = 4, min_samples_leaf=3, n_jobs=-1)\n",
    " \n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006475478893843346"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_mod = lgbm.LGBMRegressor(learning_rate = 0.05,objective = \"mae\",metric = \"mae\",num_leaves =  128,verbose =  1,random_state = 42,bagging_fraction =  0.7,feature_fraction =  0.7, n_estimators=100)\n",
    "duo_mod = lgbm.LGBMRegressor(learning_rate = 0.05,objective = \"mae\",metric = \"mae\",num_leaves =  128,verbose =  1,random_state = 42,bagging_fraction =  0.7,feature_fraction =  0.7, n_estimators=100)\n",
    "squad_mod = lgbm.LGBMRegressor(learning_rate = 0.05,objective = \"mae\",metric = \"mae\",num_leaves =  128,verbose =  1,random_state = 42,bagging_fraction =  0.7,feature_fraction =  0.7, n_estimators=100)\n",
    "\n",
    "models = [solo_mod, duo_mod, squad_mod]\n",
    "\n",
    "train_d = train_data.copy()[:2223482]\n",
    "test_d = train_data.copy()[2223482:-1]\n",
    "\n",
    "test_data_y = test_d.winPlacePerc\n",
    "test_d = test_d.drop('winPlacePerc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         prediction\n",
       " 4000001    0.045943\n",
       " 4000002    0.912115\n",
       " 4000003    0.314285\n",
       " 4000004    0.030677\n",
       " 4000005    0.043063\n",
       " ...             ...\n",
       " 4446960    0.384135\n",
       " 4446961    0.244435\n",
       " 4446962    0.319853\n",
       " 4446963    0.401720\n",
       " 4446964    0.926213\n",
       " \n",
       " [446964 rows x 1 columns],\n",
       " 0.007930814029814782)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMSE(train_d, test_d, models, test_data_y)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression # Ridge # Lasso # RandomForestRegressor #\n",
    "#lgbreg = lgb.LGBMRegressor(learning_rate = 0.05,objective = \"mae\",metric = \"mae\",num_leaves =  128,verbose =  1,random_state = 42,bagging_fraction =  0.7,feature_fraction =  0.7, n_estimators=100)\n",
    "#solo_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "#duo_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)\n",
    "#squad_mod = RandomForestRegressor(n_estimators=120, max_features=0.5, min_samples_leaf=3, n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
